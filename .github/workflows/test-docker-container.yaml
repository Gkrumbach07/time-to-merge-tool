# This is a basic workflow to help you get started with Actions
name: base container image

# Controls when the workflow will run
on:

  repository_dispatch:
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
# A workflow run is made up of one or more jobs that can run sequentially or in parallel

jobs:
  # This workflow contains a single job called "build"
  pipeline:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    container: 
      image: quay.io/aicoe/ocp-ci-analysis
    if: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID.passed }} == true
    env:
      
      AWS_ACCESS_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID}}
    
      GITHUB_REPO: ${{ github.event.client_payload.REPO || secrets.REPO }}
      GITHUB_ORG: ${{ github.event.client_payload.ORG || secrets.ORG }}

      S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
      S3_BUCKET: ${{ secrets.S3_BUCKET }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      CEPH_BUCKET: ${{ secrets.CEPH_BUCKET }}
      CEPH_BUCKET_PREFIX: ${{ secrets.CEPH_BUCKET_PREFIX }}
      CEPH_KEY_ID: ${{ secrets.CEPH_KEY_ID }}
      CEPH_SECRET_KEY: ${{ secrets.CEPH_SECRET_KEY }}

      GITHUB_ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      
      TRINO_USER: ${{ secrets.TRINO_USER }}
      TRINO_PASSWD: ${{ secrets.TRINO_PASSWD }}
      TRINO_HOST: ${{ secrets.TRINO_HOST }}
      TRINO_PORT: ${{ secrets.TRINO_PORT }}
      
      REMOTE: 1
      CHOSEN_MODEL: 'rf'

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
#       - name: Install xmllint
#         run: apt-get install build-essential libffi-dev python3 python3-dev python3-pip libfuzzy-dev
        
      - name: installs
        run: |
          yum -y install gcc gcc-c++ make python39 python3-setuptools glibc libffi automake autoconf libtool
          yum upgrade glibc
        
        
#       - name: Install dependencies
#         run: python3 -m pip install --upgrade pip -r requirements.txt
#       - name: Update data
#         run: python ./src/main.py
      - name: Data Collection notebook
        run: |
          python3 -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 01_data_collection.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 01_notebook_executed
      - name: commit updated notebook
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook"
          add: "01_notebook_executed.ipynb"
      - name: Feature Engineering notebook
        run: |
          python3 -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 02_feature_engineering.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 02_notebook_executed
      - name: commit updated notebook 2
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 2"
          add: "02_notebook_executed.ipynb"
      - name: Model Training notebook
        run: |
          python -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 03_model_training.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 03_notebook_executed
      - name: commit updated notebook 3
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 3"
          add: "03_notebook_executed.ipynb"
